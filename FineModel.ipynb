{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25906cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15868\\597578600.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, average_precision_score, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ab82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop Stage</th>\n",
       "      <th>Crop Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pre-sowing</td>\n",
       "      <td>Loose Smut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pre-sowing</td>\n",
       "      <td>Common Bunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pre-sowing</td>\n",
       "      <td>Karnal Bunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pre-sowing</td>\n",
       "      <td>Loose Smut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre-sowing</td>\n",
       "      <td>Common Bunt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Crop Stage Crop Disease\n",
       "0  pre-sowing   Loose Smut\n",
       "1  pre-sowing  Common Bunt\n",
       "2  pre-sowing  Karnal Bunt\n",
       "3  pre-sowing   Loose Smut\n",
       "4  pre-sowing  Common Bunt"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CSV_PATH = \"Data/Wheat/Wheat_Crop_Disease_Environment_Cures_Maharashtra.csv\"  # <-- change this\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "needed_cols = [\"Crop Stage\", \"Crop Disease\"]\n",
    "missing = [c for c in needed_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "df = df[needed_cols].copy()\n",
    "\n",
    "df[\"Crop Stage\"] = (\n",
    "    df[\"Crop Stage\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "df[\"Crop Disease\"] = (\n",
    "    df[\"Crop Disease\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(r\"\\s*\\|\\s*\", \"|\", regex=True) \n",
    ")\n",
    "df = df.dropna(subset=[\"Crop Stage\", \"Crop Disease\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb63d97-5a58-4718-824d-cc9b2eb82f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 19\n",
      "Classes: ['Barley Yellow Dwarf Virus (BYDV)', 'Black Point', 'Common Bunt', 'Crown Rot', 'Damping-off (Pythium)', 'Fusarium Head Blight', 'Karnal Bunt', 'Leaf Blight', 'Leaf Rust', 'Loose Smut'] ...\n"
     ]
    }
   ],
   "source": [
    "def to_label_list(s):\n",
    "    s = str(s).strip()\n",
    "    if \"|\" in s:\n",
    "        return [t.strip() for t in s.split(\"|\") if t.strip()]\n",
    "    return [s]\n",
    "\n",
    "y_list = df[\"Crop Disease\"].apply(to_label_list)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(y_list)\n",
    "\n",
    "print(\"Num classes:\", len(mlb.classes_))\n",
    "print(\"Classes:\", list(mlb.classes_)[:10], \"...\" if len(mlb.classes_) > 10 else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f801aa-49ee-4714-864e-9d0cdd9235f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Crop Stage\"]].copy()\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[(\"stage_ohe\", ohe, [\"Crop Stage\"])],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd25f9-492f-4163-b51d-fe62063fdb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping stratify on 2nd split (some stages have only 1 sample)\n",
      "Train: (98, 1) (98, 19)\n",
      "Val  : (21, 1) (21, 19)\n",
      "Test : (21, 1) (21, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stage_series = df[\"Crop Stage\"]\n",
    "\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp, stg_train, stg_temp = train_test_split(\n",
    "    X, Y, stage_series,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=stage_series\n",
    ")\n",
    "\n",
    "stage_counts = stg_temp.value_counts()\n",
    "can_stratify = (stage_counts >= 2).all()\n",
    "\n",
    "if can_stratify:\n",
    "    X_val, X_test, Y_val, Y_test, stg_val, stg_test = train_test_split(\n",
    "        X_temp, Y_temp, stg_temp,\n",
    "        test_size=0.50,\n",
    "        random_state=42,\n",
    "        stratify=stg_temp\n",
    "    )\n",
    "else:\n",
    "    print(\" Skipping stratify on 2nd split (some stages have only 1 sample)\")\n",
    "    X_val, X_test, Y_val, Y_test, stg_val, stg_test = train_test_split(\n",
    "        X_temp, Y_temp, stg_temp,\n",
    "        test_size=0.50,\n",
    "        random_state=42,\n",
    "        stratify=None \n",
    "    )\n",
    "\n",
    "print(\"Train:\", X_train.shape, Y_train.shape)\n",
    "print(\"Val  :\", X_val.shape, Y_val.shape)\n",
    "print(\"Test :\", X_test.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a28bf-ef8d-4df5-b1cd-e771db9268da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "def fit_ovr_xgb(preprocessor, X_train, Y_train, random_state=42, base_params=None):\n",
    "    \"\"\"\n",
    "    Fits one XGBClassifier per label (OvR) using preprocessed features.\n",
    "    Returns: Bunch(preprocessor, estimators, classes_)\n",
    "    \"\"\"\n",
    "    if base_params is None:\n",
    "        base_params = dict(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=1.0,\n",
    "            min_child_weight=1.0,\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "\n",
    "    Xtr = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    estimators = []\n",
    "    L = Y_train.shape[1]\n",
    "    for j in range(L):\n",
    "        yj = Y_train[:, j]\n",
    "        pos = yj.sum()\n",
    "        neg = len(yj) - pos\n",
    "        spw = float(neg / max(1.0, pos)) if pos > 0 else 1.0\n",
    "\n",
    "        clf = XGBClassifier(**{**base_params, \"scale_pos_weight\": spw})\n",
    "        clf.fit(Xtr, yj)\n",
    "        estimators.append(clf)\n",
    "\n",
    "    return Bunch(preprocessor=preprocessor, estimators=estimators, classes_=mlb.classes_)\n",
    "\n",
    "\n",
    "def predict_proba_ovr(model_bunch, X):\n",
    "    \"\"\"Return probability matrix for each class.\"\"\"\n",
    "    Xp = model_bunch.preprocessor.transform(X)\n",
    "    probs = np.column_stack([est.predict_proba(Xp)[:, 1] for est in model_bunch.estimators])\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d6dbd7-a850-46b1-a7b2-f5d477021273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation micro-F1: 0.6176\n",
      "Best params: {'n_estimators': 800, 'learning_rate': 0.03, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_lambda': 1.0, 'min_child_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_f1_micro(preproc, params):\n",
    "    mb = fit_ovr_xgb(preproc, X_train, Y_train, base_params=params)\n",
    "    P_val = predict_proba_ovr(mb, X_val)\n",
    "    Y_pred = (P_val >= 0.5).astype(int)\n",
    "    return f1_score(Y_val, Y_pred, average=\"micro\")\n",
    "\n",
    "param_space = [\n",
    "    dict(\n",
    "        n_estimators=n,\n",
    "        learning_rate=lr,\n",
    "        max_depth=md,\n",
    "        subsample=ss,\n",
    "        colsample_bytree=cs,\n",
    "        reg_lambda=rl,\n",
    "        min_child_weight=mcw,\n",
    "    )\n",
    "    for n in [300, 500, 800]\n",
    "    for lr in [0.03, 0.05, 0.08]\n",
    "    for md in [3, 4, 5]\n",
    "    for ss in [0.8, 0.9]\n",
    "    for cs in [0.8, 0.9]\n",
    "    for rl in [1.0, 2.0]\n",
    "    for mcw in [1.0, 2.0]\n",
    "]\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "sample_idx = rng.choice(len(param_space), size=min(20, len(param_space)), replace=False)\n",
    "\n",
    "best_params = None\n",
    "best_score = -1\n",
    "\n",
    "for idx in sample_idx:\n",
    "    params = param_space[idx]\n",
    "    score = evaluate_f1_micro(preproc, params)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best validation micro-F1:\", round(best_score, 4))\n",
    "print(\"Best params:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07e7093-be98-46a1-9954-5c930f2ba95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = dict(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=1.0,\n",
    ")\n",
    "if best_params is not None:\n",
    "    final_params.update(best_params)\n",
    "\n",
    "model = fit_ovr_xgb(preproc, X_train, Y_train, base_params=final_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0be21d8-0cdb-43a7-899b-7d6faa6bee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-label thresholds (first 10): [0.011 0.015 0.017 0.013 0.002 0.014 0.01  0.013 0.015 0.792]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "P_val = predict_proba_ovr(model, X_val)\n",
    "\n",
    "def best_thresholds_from_val(P, Y_true):\n",
    "    thresholds = np.zeros(P.shape[1], dtype=float)\n",
    "    for j in range(P.shape[1]):\n",
    "        pj = P[:, j]\n",
    "        yj = Y_true[:, j]\n",
    "        prec, rec, thr = precision_recall_curve(yj, pj)\n",
    "        f1s = (2 * prec * rec) / np.clip(prec + rec, 1e-12, None)\n",
    "        if len(thr) == 0:\n",
    "            thresholds[j] = 0.5\n",
    "            continue\n",
    "        best_idx = np.nanargmax(f1s[1:]) if len(f1s) > 1 else 0\n",
    "        thresholds[j] = thr[best_idx] if best_idx < len(thr) else 0.5\n",
    "    return thresholds\n",
    "\n",
    "opt_thresholds = best_thresholds_from_val(P_val, Y_val)\n",
    "print(\"Per-label thresholds (first 10):\", np.round(opt_thresholds[:10], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b7bac-0e24-4f85-b1a1-5a64bd2364e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset accuracy: 0.0\n",
      "F1 (micro): 0.25\n",
      "F1 (macro): 0.31\n",
      "mAP (macro): 0.4031\n",
      "ROC-AUC unavailable.\n",
      "\n",
      "Per-class report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "Barley Yellow Dwarf Virus (BYDV)       0.05      1.00      0.09         1\n",
      "                     Black Point       0.00      0.00      0.00         0\n",
      "                     Common Bunt       0.25      1.00      0.40         1\n",
      "                       Crown Rot       0.33      1.00      0.50         1\n",
      "           Damping-off (Pythium)       0.25      1.00      0.40         1\n",
      "            Fusarium Head Blight       0.00      0.00      0.00         0\n",
      "                     Karnal Bunt       0.05      1.00      0.09         1\n",
      "                     Leaf Blight       0.33      1.00      0.50         1\n",
      "                       Leaf Rust       0.75      1.00      0.86         3\n",
      "                      Loose Smut       0.57      1.00      0.73         4\n",
      "             Root Rot (Fusarium)       0.60      0.75      0.67         4\n",
      "                        Seed Rot       0.05      1.00      0.09         1\n",
      "      Seedling Blight (Fusarium)       0.25      1.00      0.40         1\n",
      "            Septoria Leaf Blotch       0.33      1.00      0.50         1\n",
      "             Soilborne Pathogens       0.00      0.00      0.00         0\n",
      "     Storage Fungi (Aspergillus)       0.50      1.00      0.67         1\n",
      "                     Stripe Rust       0.00      0.00      0.00         0\n",
      "              Weevil Infestation       0.00      0.00      0.00         0\n",
      "                     Yellow Rust       0.00      0.00      0.00         0\n",
      "\n",
      "                       micro avg       0.14      0.95      0.25        21\n",
      "                       macro avg       0.23      0.67      0.31        21\n",
      "                    weighted avg       0.44      0.95      0.56        21\n",
      "                     samples avg       0.15      0.95      0.26        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, average_precision_score, roc_auc_score\n",
    "\n",
    "P_test = predict_proba_ovr(model, X_test)\n",
    "Y_pred_test = (P_test >= opt_thresholds.reshape(1, -1)).astype(int)\n",
    "\n",
    "print(\"Subset accuracy:\", round(accuracy_score(Y_test, Y_pred_test), 4))\n",
    "print(\"F1 (micro):\", round(f1_score(Y_test, Y_pred_test, average='micro'), 4))\n",
    "print(\"F1 (macro):\", round(f1_score(Y_test, Y_pred_test, average='macro'), 4))\n",
    "\n",
    "try:\n",
    "    mAP = average_precision_score(Y_test, P_test, average=\"macro\")\n",
    "    print(\"mAP (macro):\", round(mAP, 4))\n",
    "except:\n",
    "    print(\"mAP unavailable.\")\n",
    "\n",
    "try:\n",
    "    auc = roc_auc_score(Y_test, P_test, average=\"macro\")\n",
    "    print(\"ROC-AUC (macro):\", round(auc, 4))\n",
    "except:\n",
    "    print(\"ROC-AUC unavailable.\")\n",
    "\n",
    "print(\"\\nPer-class report:\")\n",
    "print(classification_report(Y_test, Y_pred_test, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8edaa9a-1b53-4d70-9324-627b649c8217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
